{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 6) <class 'pandas.core.frame.DataFrame'>\n",
      "(400, 5)\n"
     ]
    }
   ],
   "source": [
    "# data_tr = pd.read_csv(\"../Datasets/Assignments/LRTrain.csv\")\n",
    "# data_test = pd.read_csv(\"../Datasets/Assignments/LRTest.csv\")\n",
    "\n",
    "data_tr = pd.read_csv(\"../Kaggle/Datasets/all/Train.csv\")\n",
    "data_test = pd.read_csv(\"../Kaggle/Datasets/all/Test.csv\")\n",
    "print(data_tr.shape, type(data_tr))\n",
    "print(data_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.293416</td>\n",
       "      <td>-0.945599</td>\n",
       "      <td>-0.421105</td>\n",
       "      <td>0.406816</td>\n",
       "      <td>0.525662</td>\n",
       "      <td>-82.154667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.836084</td>\n",
       "      <td>-0.189228</td>\n",
       "      <td>-0.776403</td>\n",
       "      <td>-1.053831</td>\n",
       "      <td>0.597997</td>\n",
       "      <td>-48.897960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.236425</td>\n",
       "      <td>0.132836</td>\n",
       "      <td>-0.147723</td>\n",
       "      <td>0.699854</td>\n",
       "      <td>-0.187364</td>\n",
       "      <td>77.270371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.175312</td>\n",
       "      <td>0.143194</td>\n",
       "      <td>-0.581111</td>\n",
       "      <td>-0.122107</td>\n",
       "      <td>-1.292168</td>\n",
       "      <td>-2.988581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.693011</td>\n",
       "      <td>0.542712</td>\n",
       "      <td>-2.798729</td>\n",
       "      <td>-0.686723</td>\n",
       "      <td>1.244077</td>\n",
       "      <td>-37.596722</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5     target\n",
       "0   0.293416  -0.945599  -0.421105   0.406816   0.525662 -82.154667\n",
       "1  -0.836084  -0.189228  -0.776403  -1.053831   0.597997 -48.897960\n",
       "2   0.236425   0.132836  -0.147723   0.699854  -0.187364  77.270371\n",
       "3   0.175312   0.143194  -0.581111  -0.122107  -1.292168  -2.988581\n",
       "4  -1.693011   0.542712  -2.798729  -0.686723   1.244077 -37.596722"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 6) <class 'numpy.ndarray'>\n",
      "(400, 5) <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "data_tr = data_tr.values\n",
    "data_test = data_test.values\n",
    "\n",
    "print(data_tr.shape, type(data_tr))\n",
    "print(data_test.shape, type(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 5) (1600, 1)\n",
      "(1600, 6) (1600, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train = data_tr[:, :5]\n",
    "Y_train = data_tr[:, -1:]\n",
    "\n",
    "X_test = data_test[:, :5]\n",
    "X_test = np.hstack((np.ones((X_test.shape[0],1)), X_test))\n",
    "# Y_test = data_test[:, -1:]\n",
    "\n",
    "print(X_train.shape, Y_train.shape)     # => Number of features in dataset = 5\n",
    "X_train = np.hstack((np.ones((X_train.shape[0],1)), X_train))\n",
    "print(X_train.shape, Y_train.shape)     # => Number of features in dataset = 5\n",
    "\n",
    "# print(X_test.shape, Y_test.shape)     # => Number of features in dataset = 5\n",
    "\n",
    "# print(X_train)\n",
    "ft = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypothesis(x, theta):\n",
    "    rv = 0\n",
    "    for i in range(ft+1):\n",
    "        rv += theta[i]*x[i]\n",
    "    return rv\n",
    "\n",
    "def error(X, Y, theta):\n",
    "    m = X.shape[0]\n",
    "    total_error = 0\n",
    "    for i in range(m):\n",
    "        hx = hypothesis(X[i], theta)\n",
    "        total_error += ((hx - Y[i])**2)\n",
    "    return total_error/2\n",
    "\n",
    "def gradient(X, Y, theta):\n",
    "    m = X.shape[0]\n",
    "    grad = np.zeros((ft+1,))\n",
    "    \n",
    "    for i in range(m):\n",
    "        for j in range(ft+1):\n",
    "            hxi = hypothesis(X[i], theta)\n",
    "            grad[j] += (hxi - Y[i])*X[i][j]\n",
    "    return grad\n",
    "        \n",
    "def gradientDescent(X, Y, lr = 0.001):\n",
    "    m = X.shape[0]\n",
    "    theta = np.random.randn(ft+1,)\n",
    "    error_list = []\n",
    "    theta_list = []\n",
    "    \n",
    "    prev_e = 0\n",
    "    e = np.inf\n",
    "    \n",
    "    while abs(e - prev_e) >= 0.0000000001:\n",
    "#     for i in range(1000):\n",
    "        grad = gradient(X, Y, theta)\n",
    "        prev_e = e\n",
    "        e = error(X, Y, theta)\n",
    "        error_list.append(e)\n",
    "        theta_list.append(theta)\n",
    "        \n",
    "        for j in range(ft+1):\n",
    "            theta[j] = theta[j] - lr*grad[j]\n",
    "            \n",
    "    return theta, error_list, theta_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.99096668 29.68187113 92.66247751  8.28062101 44.76773528  2.51916115]\n",
      "78 78\n"
     ]
    }
   ],
   "source": [
    "final_theta, error_list, theta_list = gradientDescent(X_train, Y_train)\n",
    "print(final_theta)\n",
    "print(len(theta_list), len(error_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "plt.plot(error_list)\n",
    "plt.show()\n",
    "print(len(error_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score with Gradient Descent on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.zeros(Y_train.shape)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "for i in range(m):\n",
    "    y_pred[i] = hypothesis(X_train[i], final_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1600, 1) (1600, 1)\n",
      "0.9660939669975617\n"
     ]
    }
   ],
   "source": [
    "# Coefficient of Determination\n",
    "\n",
    "print(Y_train.shape, y_pred.shape)\n",
    "u = ((Y_train - y_pred)**2).sum()\n",
    "v = ((Y_train - Y_train.mean())**2).sum()\n",
    "\n",
    "r2 = 1.0 - u/v\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score with Gradient Descent on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncols = []\\nfor i in range(y_pred_test.shape[0]):\\n    cols.append(i)\\ncols = np.array(cols)\\ncols = cols.reshape((400, 1))\\n\\nfinal_y = np.hstack((cols, y_pred_test))\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test = np.zeros(X_test.shape[0])\n",
    "m = X_test.shape[0]\n",
    "for i in range(m):\n",
    "    y_pred_test[i] = hypothesis(X_test[i], final_theta)\n",
    "'''\n",
    "cols = []\n",
    "for i in range(y_pred_test.shape[0]):\n",
    "    cols.append(i)\n",
    "cols = np.array(cols)\n",
    "cols = cols.reshape((400, 1))\n",
    "\n",
    "final_y = np.hstack((cols, y_pred_test))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-85c8ce201fc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_test\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Y_test' is not defined"
     ]
    }
   ],
   "source": [
    "u = ((Y_test - y_pred_test)**2).sum()\n",
    "v = ((Y_test - Y_test.mean())**2).sum()\n",
    "\n",
    "r2 = 1.0 - u/v\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_grad(X, Y, theta, bsize=1):\n",
    "    m = X.shape[0]\n",
    "    indices = np.arange(m)\n",
    "    np.random.shuffle(indices)    \n",
    "    \n",
    "    indices = indices[: bsize]    \n",
    "    grad = np.zeros((ft+1,))\n",
    "    \n",
    "    for i in indices:   \n",
    "        for j in range(ft+1):\n",
    "            hxi = hypothesis(X[i], theta)\n",
    "            grad[j] += (hxi - Y[i])*X[i][j]\n",
    "    return grad\n",
    "\n",
    "def gradientDescentStochastic(X, Y, lr = 0.001):\n",
    "    m = X.shape[0]\n",
    "    theta = np.random.randn(ft+1,)\n",
    "    error_list = []\n",
    "    theta_list = []\n",
    "    \n",
    "    prev_avg_e = 0\n",
    "    avg_error = np.inf    # Avg error over last 100 epochs\n",
    "    e = np.inf\n",
    "    i = 0\n",
    "    \n",
    "    while abs(prev_avg_e - avg_error) >= 100:\n",
    "#     for i in range(1000):\n",
    "        grad = batch_grad(X, Y, theta)\n",
    "        e = error(X, Y, theta)\n",
    "#         if i % 10:\n",
    "        error_list.append(e)\n",
    "        theta_list.append(theta)\n",
    "\n",
    "        for j in range(ft+1):\n",
    "            theta[j] = theta[j] - lr*grad[j]\n",
    "       \n",
    "        elx = np.array(error_list[-200:-100])\n",
    "        prev_avg_e = elx.sum()/100\n",
    "        el = np.array(error_list[-100:])\n",
    "        avg_error = el.sum()/100\n",
    "            \n",
    "    return theta, error_list, theta_list    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training with Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_theta2, error_list2, theta_list2 = gradientDescentStochastic(X_train, Y_train)\n",
    "print(final_theta2)\n",
    "print(len(theta_list2), len(error_list2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(error_list2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = np.zeros(Y_train.shape)\n",
    "\n",
    "m = X_train.shape[0]\n",
    "for i in range(m):\n",
    "    y_pred2[i] = hypothesis(X_train[i], final_theta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficient of Determination\n",
    "u = ((Y_train - y_pred2)**2).sum()\n",
    "v = ((Y_train - Y_train.mean())**2).sum()\n",
    "\n",
    "r2 = 1.0 - u/v\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test2 = np.zeros(X_test.shape[0])\n",
    "m = X_test.shape[0]\n",
    "for i in range(m):\n",
    "    y_pred_test2[i] = hypothesis(X_test[i], final_theta2)\n",
    "    \n",
    "    \n",
    "'''cols = []\n",
    "for i in range(y_pred_test2.shape[0]):\n",
    "    cols.append(i)\n",
    "cols = np.array(cols)\n",
    "cols = cols.reshape((400, 1))\n",
    "\n",
    "final_y = np.hstack((cols, y_pred_test2))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = ((Y_test - y_pred_test2)**2).sum()\n",
    "v = ((Y_test - Y_test.mean())**2).sum()\n",
    "\n",
    "r2 = 1.0 - u/v\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verifying parameters and R2 using library functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.99096674] [[ 0.         29.68187118 92.66247759  8.28062089 44.76773522  2.51916121]]\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "print(model.intercept_, model.coef_)\n",
    "# [ 4.99096674                29.68187118 92.66247759  8.28062089 44.76773522  2.51916121]\n",
    "# [ 4.99096668                29.68187113 92.66247751  8.28062101 44.76773528  2.51916115]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.score(X_train, Y_train))\n",
    "print(model.score(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(y_pred_test)\n",
    "dff.to_csv(\"aqp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(y_pred_test2)\n",
    "dff.to_csv(\"aqp2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
