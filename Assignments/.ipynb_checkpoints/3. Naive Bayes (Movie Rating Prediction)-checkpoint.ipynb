{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Read training data (reviews) and training results (ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datasets/Movie Rating Prediction/imdb_trainX.txt') as f:\n",
    "    reviews = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratings = pd.read_csv('../Datasets/Movie Rating Prediction/imdb_trainY.txt', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0\n",
       "0  10\n",
       "1   8\n",
       "2   7\n",
       "3   8\n",
       "4   8"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_ratings.shape)\n",
    "train_ratings.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 <class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews), type(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements, prolonged scenes of disastor, nudity/sexuality and some language.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2970\n"
     ]
    }
   ],
   "source": [
    "# print(reviews[1])\n",
    "print(len(reviews[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Clean (tokenize, remove stopwords, and stem) reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = RegexpTokenizer(r'\\w+')\n",
    "sw = stopwords.words('english')\n",
    "ss = SnowballStemmer('english')\n",
    "ls = LancasterStemmer()\n",
    "ps = PorterStemmer()\n",
    "l = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_review(review):\n",
    "    review = review.lower()\n",
    "    review = review.replace(\"<br />\", \" \")\n",
    "    \n",
    "    words = tk.tokenize(review)\n",
    "    filt_words = [w for w in words if (w not in sw or w == 'not')]\n",
    "#     stemmed_words = [ss.stem(w) for w in filt_words]\n",
    "    stemmed_words = [l.lemmatize(w) for w in filt_words]\n",
    "    \n",
    "    clean_rev = ' '.join(stemmed_words)\n",
    "    return clean_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I loved this movie since I was 7 and I saw it on the opening day. It was so touching and beautiful. I strongly recommend seeing for all. It's a movie to watch with your family by far.<br /><br />My MPAA rating: PG-13 for thematic elements, prolonged scenes of disastor, nudity/sexuality and some language.\n",
      "\n",
      "loved movie since 7 saw opening day touching beautiful strongly recommend seeing movie watch family far mpaa rating pg 13 thematic element prolonged scene disastor nudity sexuality language\n",
      "1849\n"
     ]
    }
   ],
   "source": [
    "print(reviews[0])\n",
    "print(clean_review(reviews[0]))\n",
    "print(len(clean_review(reviews[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "clean_reviews = [clean_review(x) for x in reviews]\n",
    "print(len(clean_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My observations: vamp outfit at end is ravishing and wonderful, exotic and fantastic. Jeanette wore it well, and got even with naive Nelson. Boat crashing into his balcony served him right. Costume outfits of his female mafia were designed surprisingly well, especially by today's standards. 1942 costume designer did great job. Main song theme just lovely.<br /><br />Caution to negative posters: 1942 was time of WW II; Pearl Harbor happened year before. U.S. just coming out of Great Depression; needed to get out and spend that hard earned money on diversion of singing, dance and yes, fantastic fantasy. Despotic dictators were trying to rule out there in RL, snuffing out freedoms. Thank goodness the public had these fantastic plot line movies to attend. Movie going was a privileged treat, in those depressing times. When you, negative posters, become actors or even movie stars, then YOU have room to talk and criticize. Jeanette's and Nelson's movies stand the test of time.<br /><br />Angel wings wonderful, on the real angel. RL wings at costume party not so hot, but great on Jeanette considering the SL.<br /><br />Beautiful singing by Jeanette and Nelson, as always. Jeanette dancing was a pure delight.<br /><br />15/10\n",
      "\n",
      "\n",
      "observ vamp outfit end ravish wonder exot fantast jeanett wore well got even naiv nelson boat crash balconi serv right costum outfit femal mafia design surprisingli well especi today standard 1942 costum design great job main song theme love caution neg poster 1942 time ww ii pearl harbor happen year u come great depress need get spend hard earn money divers sing danc ye fantast fantasi despot dictat tri rule rl snuf freedom thank good public fantast plot line movi attend movi go privileg treat depress time neg poster becom actor even movi star room talk critic jeanett nelson movi stand test time angel wing wonder real angel rl wing costum parti not hot great jeanett consid sl beauti sing jeanett nelson alway jeanett danc pure delight 15 10\n"
     ]
    }
   ],
   "source": [
    "print(reviews[321])\n",
    "print()\n",
    "print(clean_reviews[321])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create vocab\n",
    "vocab = {}\n",
    "\n",
    "for r in clean_reviews:\n",
    "    words = tk.tokenize(r)\n",
    "    for w in words:\n",
    "        if vocab.get(w):\n",
    "            ov = vocab.get(w)\n",
    "            vocab[w] = ov+1\n",
    "        else:\n",
    "            vocab[w] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(vocab))\n",
    "# print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = []\n",
    "x.extend([[1,2]])\n",
    "x.extend([[3,4]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create frequency vector\n",
    "\n",
    "freq = []\n",
    "for r in clean_reviews:\n",
    "    f = []\n",
    "    words = tk.tokenize(r)\n",
    "    for k in vocab.keys():\n",
    "        f.extend([r.count(k)])\n",
    "    freq.extend([f])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(freq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = np.array(freq)\n",
    "print(freq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = freq\n",
    "Y = train_ratings.values.reshape((-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (25000,)\n"
     ]
    }
   ],
   "source": [
    "print(type(Y), (Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(Y.reshape((-1,))[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScikitLearn Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb = MultinomialNB()\n",
    "# gnb = GaussianNB()\n",
    "# bnb = BernoulliNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X, Y.reshape((-1,)))\n",
    "# gnb.fit(X, Y.reshape((-1,)))\n",
    "# bnb.fit(X, Y.reshape((-1,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mnb.score(X, Y))\n",
    "print(gnb.score(X, Y))\n",
    "print(bnb.score(X, Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.predict(freq[1].reshape((1,-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../Datasets/Movie Rating Prediction/imdb_testX.txt') as ff:\n",
    "    testers = ff.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = pd.read_csv(\"../Datasets/Movie Rating Prediction/imdb_testY.txt\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_y.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The problem with so many people watching this movie is the mindset they watch it in. People come looking for a B-Grade horror film, or a \"So Bad It's Good\" movie. Jack Frost 2 is neither of these.<br /><br />It is, to put it simply, a very good movie cleverly hidden inside a very bad one. To view it as anything other than a screwball comedy (easily funnier than all three absolutely meritless \"Scary Movies\" combined) is to misinterpret the movie on a basic level. It would be like watching Shawshank Redemption and then complaining that there were no explosions.<br /><br />The premise is simple; the characters from the first movie, haunted by memories of Jack Frost, take a vacation to a tropical island. A new, improved Jack comes after them, now with essentially the powers of Hydro-Man from Spider-Man; essentially, he can turn from water to snow easily and quickly, divide himself, multiply himself, and, worst of all, he's managed to grow an immunity to his only former weakness...AntiFreeze.<br /><br />What's sad about this movie is that the brain dead fans of the first Jack Frost (a simply HORRIBLE movie) can't appreciate the change of tone for the sequel. Just as Alien was a horror film and Aliens was all about action, Jack Frost was a weak attempt at gimmick horror and Jack Frost 2 is a cleverly written parody of the gimmick horror genre.<br /><br />Most of the entertainment comes the live action actors, who serve admirably. Particularly funny among them are Ray Tooney (playing a caricature of a retired British Colonel from the early 1900s), Christopher Allport (offering an insane, hilarious spin on his wooden performance from the first film), and David Allen Brooks (taking the once serious role of manners to new, totally bizarre heights).<br /><br />The lack of \"memorable quotes\" disturbs me.<br /><br />As a horror movie, Jack Frost 2: Revenge of The Mutant Killer Snowman, rates a zero. But you have to understand, IT'S NOT A HORROR MOVIE.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(testers[503])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "print(len(testers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 1)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "y_test = y_test.reshape((-1,))\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ],
   "source": [
    "clean_test = [clean_review(x) for x in testers]\n",
    "print(len(clean_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test[503]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = []\n",
    "for rt in clean_test:\n",
    "    f1 = []\n",
    "    words = tk.tokenize(rt)\n",
    "    for k in vocab.keys():\n",
    "        f1.extend([rt.count(k)])\n",
    "    test_freq.extend([f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_freq = np.array(test_freq)\n",
    "print(test_freq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_freq\n",
    "Y_test = y_test\n",
    "print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = mnb.predict(X_test)\n",
    "# np.sum((res == Y_test)/Y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "$ P(Y|X) = \\frac{P(Y) P(X|Y)}{P(X)} = \\frac{P(Y) \\Pi_{i=1}^{n} P(x_i | y = c)}{P(X)} $ \n",
    "\n",
    "where, \n",
    "- P(Y) is prior probability\n",
    "- P(X|Y) is conditional probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_prob(y_train, label):\n",
    "    total_examples = y_train.shape[0]\n",
    "    label_examples = np.sum(y_train == label)\n",
    "    return np.log(label_examples/float(total_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Rating = 1:\", prior_prob(Y, 1))\n",
    "# print(\"Rating = 2:\", prior_prob(Y, 2))\n",
    "# print(\"Rating = 3:\", prior_prob(Y, 3))\n",
    "# print(\"Rating = 4:\", prior_prob(Y, 4))\n",
    "# print(\"Rating = 5:\", prior_prob(Y, 5))\n",
    "# print(\"Rating = 6:\", prior_prob(Y, 6))\n",
    "# print(\"Rating = 7:\", prior_prob(Y, 7))\n",
    "# print(\"Rating = 8:\", prior_prob(Y, 8))\n",
    "# print(\"Rating = 9:\", prior_prob(Y, 9))\n",
    "# print(\"Rating = 10:\", prior_prob(Y, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_classifier(reviews):\n",
    "    review_class = [[], [], [], [], [], [], [], [], [], []]\n",
    "    for i in range(len(reviews)):\n",
    "        review_class[-1+Y[i]].extend([reviews[i]])\n",
    "    return review_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_class = review_classifier(clean_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "classwise_vocab = [{}, {}, {}, {}, {}, {}, {}, {}, {}, {}]\n",
    "sum_classwise_vocab = []\n",
    "\n",
    "def create_class_vocab(review_class):  \n",
    "    for c in range(1, 11):\n",
    "        for review in review_class[-1+c]:\n",
    "            words = tk.tokenize(review)\n",
    "            for w in words:\n",
    "                if classwise_vocab[-1+c].get(w):\n",
    "                    ov = classwise_vocab[-1+c].get(w)\n",
    "                    classwise_vocab[-1+c][w] = ov+1\n",
    "                else:\n",
    "                    classwise_vocab[-1+c][w] = 1\n",
    "        sum_classwise_vocab.extend([np.sum(list(classwise_vocab[-1+c].values()))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_class_vocab(review_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_count(xi, c):\n",
    "    if classwise_vocab[-1+c].get(xi) == None:\n",
    "        return 0\n",
    "    else:\n",
    "        return classwise_vocab[-1+c][xi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cond_prob(review, c):\n",
    "    prod = 0.0\n",
    "    words = tk.tokenize(review)\n",
    "\n",
    "    for word in words:\n",
    "        wc = word_count(word, c)\n",
    "#         print(wc)\n",
    "        sum_vocab_count = sum_classwise_vocab[-1+c] + len(classwise_vocab[-1+c])\n",
    "        if sum_vocab_count != 0:\n",
    "            prod = prod + np.log((wc+1)/float(sum_vocab_count))\n",
    "#         print(prod)\n",
    "    return prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.5896352851379207, -2.392947533074437, -2.3351082846996056, -2.22710663181814, -inf, -inf, -2.3041863743610196, -2.117268027220293, -2.4021844582168006, -1.6645278787520603]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/riagupta/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: RuntimeWarning: divide by zero encountered in log\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "prior_probs = []\n",
    "for i in range(1, 11):\n",
    "    prior_probs.append(prior_prob(Y, i))\n",
    "    \n",
    "print(prior_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(review):\n",
    "#     clean_rev = clean_review(review)\n",
    "    posterior_probs = []\n",
    "#     classes = np.unique(Y)\n",
    "    \n",
    "    for c in range(1,11):\n",
    "        if c == 5 or c == 6:\n",
    "            posterior_probs.append(-np.inf)\n",
    "            continue\n",
    "        prior = prior_probs[-1+c]\n",
    "        cond = cond_prob(review, c)\n",
    "#         print(cond)\n",
    "        post = prior + cond\n",
    "        posterior_probs.append(post)\n",
    "    \n",
    "    posterior_probs = np.array(posterior_probs)\n",
    "#     print(posterior_probs)\n",
    "    pred = np.argmax(posterior_probs)\n",
    "    return pred+1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(clean_reviews[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.856\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on Training Set\n",
    "preds = []\n",
    "for i in range(Y.shape[0]):\n",
    "    pred = predict(clean_reviews[i])\n",
    "    preds.append(pred)\n",
    "preds = np.array(preds)\n",
    "accuracy = np.sum(preds == Y)/Y.shape[0]\n",
    "print(accuracy*100)\n",
    "# 70.364 ps\n",
    "# 74.328 ss\n",
    "# 75.856 lemma & add |V|\n",
    "# 71.44 ss + |V|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  3,  8, 10,  8, 10,  3, 10,  1,  8,  8, 10,  8,  8,  8, 10,\n",
       "        8,  8,  7,  8,  7,  8,  9,  8, 10, 10, 10,  7,  9,  9,  7,  1, 10,\n",
       "       10, 10,  3,  9, 10,  1, 10,  9, 10,  8,  8, 10,  9, 10, 10,  8,  8,\n",
       "        7,  8,  8,  7,  7, 10, 10,  7, 10,  2,  9, 10,  8,  7, 10, 10, 10,\n",
       "        7, 10, 10,  7,  8,  8, 10,  1, 10,  8, 10, 10,  9,  9,  8, 10,  9,\n",
       "        7,  9, 10, 10,  7,  7, 10,  1,  7,  1, 10,  8,  8, 10, 10])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10,  8,  7,  8,  8,  8, 10,  9, 10,  8,  8,  8, 10,  8,  8,  8,  9,\n",
       "       10,  7,  7,  8,  7,  8,  9,  8,  7, 10, 10,  7,  9,  9,  7, 10, 10,\n",
       "       10, 10,  7,  9, 10,  9, 10,  9, 10,  8,  8, 10,  8, 10,  8,  8,  8,\n",
       "        7,  8,  8,  7,  7, 10, 10,  7, 10,  7,  9, 10,  8,  7, 10, 10, 10,\n",
       "        7, 10, 10,  8,  8,  8, 10, 10, 10,  8, 10, 10,  9,  9,  8,  8,  9,\n",
       "        7,  9, 10, 10,  7,  7, 10, 10,  7,  7, 10,  8,  8, 10, 10])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35.532000000000004\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on Test Set\n",
    "preds = []\n",
    "# clean_test = clean_review(testers)\n",
    "for i in range(y_test.shape[0]):\n",
    "    pred = predict(clean_test[i])\n",
    "    preds.append(pred)\n",
    "preds = np.array(preds)\n",
    "accuracy = np.sum(preds == y_test)/y_test.shape[0]\n",
    "print(accuracy*100)\n",
    "# 33.64 ps\n",
    "# 33.739999999999995 ss\n",
    "# 35.504000000000005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  2,  3,  4,  7,  8,  9, 10])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 1, 1, ..., 1, 1, 1]), array([2, 2, 2, ..., 2, 2, 2]), array([3, 3, 3, ..., 3, 3, 3]), array([4, 4, 4, ..., 4, 4, 4]), array([5, 5, 5, ..., 5, 5, 5]), array([6, 6, 6, ..., 6, 6, 6]), array([7, 7, 7, ..., 7, 7, 7]), array([8, 8, 8, ..., 8, 8, 8]), array([9, 9, 9, ..., 9, 9, 9]), array([10, 10, 10, ..., 10, 10, 10])]\n"
     ]
    }
   ],
   "source": [
    "# Accuracy on predicting Random Value on test set\n",
    "acc = []\n",
    "for i in range(1, 11):\n",
    "    acc.extend([np.array([i]*25000)])\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating 1 => 20.088\n",
      "Rating 2 => 9.208\n",
      "Rating 3 => 10.164\n",
      "Rating 4 => 10.54\n",
      "Rating 5 => 0.0\n",
      "Rating 6 => 0.0\n",
      "Rating 7 => 9.228\n",
      "Rating 8 => 11.4\n",
      "Rating 9 => 9.376\n",
      "Rating 10 => 19.996\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 11):\n",
    "    print(\"Rating %d =>\"%i, 100*np.sum(acc[i-1] == y_test)/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 1,  2,  3,  4,  7,  8,  9, 10]), array([5022, 2302, 2541, 2635, 2307, 2850, 2344, 4999]))\n",
      "(array([ 1,  2,  3,  4,  7,  8,  9, 10]), array([6118, 3570, 2548, 1997, 1954, 1453, 3114, 4246]))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_test, return_counts=True))\n",
    "print(np.unique(preds, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 30201\n",
      "2284 22729\n",
      "2420 24729\n",
      "2696 26925\n",
      "0 0\n",
      "0 0\n",
      "2496 26568\n",
      "3009 28441\n",
      "2263 24473\n",
      "4732 30781\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(len(review_class[i]), len(classwise_vocab[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classwise_vocab[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
